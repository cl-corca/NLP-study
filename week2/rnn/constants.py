# number of epoch in training
MAX_WORDS = 25
BATCH_SIZE = 1024
EPOCHS = 15
LR = 1e-3

#tokenizer constants 
MIN_WORD_FREQUENCY = 50
MAX_SEQUENCE_LENGTH = 256
MAX_TOKEN = 30000

#save model 
DIR_W = '/data'
